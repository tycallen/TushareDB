"""
æ¿å—ä¼ å¯¼å…³ç³»å…¨å†å²åˆ†æï¼ˆ2000-2026ï¼‰- L3ä¸‰çº§è¡Œä¸š

åˆ†æL3ä¸‰çº§è¡Œä¸šåœ¨å…¨éƒ¨å†å²æ•°æ®ä¸­çš„ä¼ å¯¼å…³ç³»æ¼”å˜

æ³¨æ„ï¼šL3åˆ†ç±»ä½“ç³»åœ¨ä¸åŒå¹´ä»½å¯èƒ½æœ‰å˜åŒ–ï¼Œæ—©æœŸæ•°æ®å¯èƒ½ä¸å®Œæ•´
"""

import sys
from pathlib import Path
import pandas as pd
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'src'))

from tushare_db import DataReader
from tushare_db.sector_analysis import SectorAnalyzer, OutputManager

def _get_valid_l3_sectors(db_path: str, start_date: str, end_date: str, min_stocks: int = 10) -> set:
    """è·å–æŒ‡å®šæ—¶æœŸæœ‰æ•ˆçš„L3æ¿å—ï¼ˆæˆåˆ†è‚¡æ•°>=min_stocksï¼‰"""
    reader = DataReader(db_path=db_path)

    query = f"""
        SELECT l3_code, COUNT(DISTINCT ts_code) as stock_count
        FROM index_member_all
        WHERE is_new = 'Y'
        AND l3_code IS NOT NULL
        AND in_date <= '{end_date}'
        AND (out_date IS NULL OR out_date >= '{start_date}')
        GROUP BY l3_code
        HAVING stock_count >= {min_stocks}
    """

    df = reader.db.con.execute(query).fetchdf()
    valid_sectors = set(df['l3_code'].tolist())

    reader.close()
    return valid_sectors


def main():
    """æ‰§è¡Œå…¨å†å²L3åˆ†æ"""

    # åˆå§‹åŒ–
    db_path = str(project_root / "tushare.db")
    analyzer = SectorAnalyzer(db_path)

    # å®šä¹‰åˆ†ææ—¶æœŸï¼ˆæŒ‰å¸‚åœºå‘¨æœŸåˆ’åˆ†ï¼‰
    periods = [
        {
            'name': '2000-2005å¹´',
            'start': '20000101',
            'end': '20051231',
            'description': 'è‚¡æƒåˆ†ç½®æ”¹é©å‰'
        },
        {
            'name': '2006-2008å¹´',
            'start': '20060101',
            'end': '20081231',
            'description': 'ç‰›å¸‚åŠé‡‘èå±æœº'
        },
        {
            'name': '2009-2012å¹´',
            'start': '20090101',
            'end': '20121231',
            'description': 'å››ä¸‡äº¿åˆºæ¿€åŠåç»­'
        },
        {
            'name': '2013-2015å¹´',
            'start': '20130101',
            'end': '20151231',
            'description': 'åˆ›ä¸šæ¿ç‰›å¸‚åŠè‚¡ç¾'
        },
        {
            'name': '2016-2018å¹´',
            'start': '20160101',
            'end': '20181231',
            'description': 'ä¾›ç»™ä¾§æ”¹é©'
        },
        {
            'name': '2019-2021å¹´',
            'start': '20190101',
            'end': '20211231',
            'description': 'ç–«æƒ…å†²å‡»åŠæ¢å¤'
        },
        {
            'name': '2022-2024å¹´',
            'start': '20220101',
            'end': '20241231',
            'description': 'ç»æµè½¬å‹æœŸ'
        }
    ]

    # åˆ†æå‚æ•°
    level = 'L3'
    period_type = 'daily'
    min_correlation = 0.20
    max_lag = 5
    min_sector_stocks = 10  # L3æ¿å—æœ€å°æˆåˆ†è‚¡æ•°

    print("=" * 80)
    print(f"æ¿å—ä¼ å¯¼å…³ç³»å…¨å†å²åˆ†æ - {level}å±‚çº§")
    print("=" * 80)
    print(f"åˆ†ææ–¹æ³•: è¶…é¢æ”¶ç›Šæ³•ï¼ˆå‰”é™¤å¸‚åœºæ•ˆåº”ï¼‰")
    print(f"æœ€å°ç›¸å…³ç³»æ•°: {min_correlation}")
    print(f"æœ€å¤§æ»åæœŸ: {max_lag}å¤©")
    print(f"L3æ¿å—è¿‡æ»¤: æˆåˆ†è‚¡æ•° >= {min_sector_stocks}")
    print(f"åˆ†ææ—¶æœŸæ•°: {len(periods)}")
    print()

    # å­˜å‚¨æ¯ä¸ªæ—¶æœŸçš„ç»“æœ
    all_periods_results = []

    # éå†æ¯ä¸ªæ—¶æœŸ
    for idx, period in enumerate(periods, 1):
        print(f"[{idx}/{len(periods)}] åˆ†ææ—¶æœŸ: {period['name']} ({period['description']})")
        print(f"  æ—¥æœŸèŒƒå›´: {period['start']} ~ {period['end']}")

        # è·å–è¯¥æ—¶æœŸçš„æœ‰æ•ˆL3æ¿å—
        valid_l3_sectors = _get_valid_l3_sectors(
            db_path, period['start'], period['end'], min_sector_stocks
        )
        print(f"  æœ‰æ•ˆL3æ¿å—: {len(valid_l3_sectors)} ä¸ªï¼ˆæˆåˆ†è‚¡>={min_sector_stocks}ï¼‰")

        if len(valid_l3_sectors) < 10:
            print(f"  âš ï¸  æœ‰æ•ˆæ¿å—è¿‡å°‘ï¼Œè·³è¿‡æ­¤æ—¶æœŸ")
            print()
            continue

        try:
            # è®¡ç®—ä¼ å¯¼å…³ç³»
            lead_lag_df = analyzer.calculate_lead_lag_excess(
                start_date=period['start'],
                end_date=period['end'],
                max_lag=max_lag,
                level=level,
                period=period_type,
                min_correlation=min_correlation
            )

            # è¿‡æ»¤ï¼šåªä¿ç•™æœ‰æ•ˆL3æ¿å—ä¹‹é—´çš„ä¼ å¯¼
            if len(lead_lag_df) > 0:
                lead_lag_df = lead_lag_df[
                    lead_lag_df['sector_lead'].isin(valid_l3_sectors) &
                    lead_lag_df['sector_lag'].isin(valid_l3_sectors)
                ]

            # æ·»åŠ æ—¶æœŸæ ‡è¯†
            lead_lag_df['period_name'] = period['name']
            lead_lag_df['period_start'] = period['start']
            lead_lag_df['period_end'] = period['end']

            print(f"  æ‰¾åˆ°ä¼ å¯¼å¯¹: {len(lead_lag_df)}")

            if len(lead_lag_df) > 0:
                # æ˜¾ç¤ºæœ€å¼ºçš„3ä¸ªä¼ å¯¼å…³ç³»
                top_3 = lead_lag_df.nlargest(3, 'correlation')
                print("  Top 3 ä¼ å¯¼å…³ç³»:")
                for _, row in top_3.iterrows():
                    lead_name = row.get('sector_lead_name', row['sector_lead'])
                    lag_name = row.get('sector_lag_name', row['sector_lag'])
                    print(f"    {lead_name} â†’ {lag_name}: "
                          f"r={row['correlation']:.3f}, lag={row['lag_days']}å¤©")
            else:
                print("  æœªæ‰¾åˆ°æ˜¾è‘—ä¼ å¯¼å…³ç³»")

            all_periods_results.append(lead_lag_df)
            print()

        except Exception as e:
            print(f"  âš ï¸  åˆ†æå¤±è´¥: {str(e)}")
            print()
            import traceback
            traceback.print_exc()
            continue

    # åˆå¹¶æ‰€æœ‰æ—¶æœŸçš„ç»“æœ
    if not all_periods_results:
        print("æ‰€æœ‰æ—¶æœŸå‡æœªæ‰¾åˆ°ä¼ å¯¼å…³ç³»ï¼Œåˆ†æç»“æŸã€‚")
        return

    combined_df = pd.concat(all_periods_results, ignore_index=True)

    # ç¨³å®šæ€§åˆ†æ
    print("=" * 80)
    print("ç¨³å®šæ€§åˆ†æ")
    print("=" * 80)

    # åˆ›å»ºä¼ å¯¼å¯¹çš„å”¯ä¸€æ ‡è¯†
    combined_df['pair_id'] = (
        combined_df['sector_lead'].astype(str) + '_' +
        combined_df['sector_lag'].astype(str)
    )

    # ç»Ÿè®¡æ¯ä¸ªä¼ å¯¼å¯¹å‡ºç°çš„æ¬¡æ•°
    pair_counts = combined_df.groupby('pair_id').agg({
        'period_name': lambda x: list(x),
        'sector_lead': 'first',
        'sector_lag': 'first',
        'sector_lead_name': 'first',
        'sector_lag_name': 'first',
        'correlation': 'mean',
        'lag_days': 'mean'
    }).reset_index()

    pair_counts['appearance_count'] = pair_counts['period_name'].apply(len)
    pair_counts = pair_counts.sort_values('appearance_count', ascending=False)

    total_periods = len([p for p in periods])
    stable_all = pair_counts[pair_counts['appearance_count'] == total_periods]
    stable_half = pair_counts[pair_counts['appearance_count'] >= total_periods // 2]

    print(f"\nåˆ†ææ—¶æœŸæ•°: {total_periods}")
    print(f"æ€»ä¼ å¯¼å¯¹æ•°: {len(pair_counts)}")
    print(f"å‡ºç°åœ¨æ‰€æœ‰æ—¶æœŸ: {len(stable_all)} å¯¹")
    print(f"å‡ºç°åœ¨>=ä¸€åŠæ—¶æœŸ: {len(stable_half)} å¯¹")
    print()

    # æ˜¾ç¤ºè·¨æ—¶æœŸæœ€ç¨³å®šçš„ä¼ å¯¼å…³ç³»
    if len(stable_all) > 0:
        print("\nğŸ”¥ è·¨è¶Šå…¨éƒ¨æ—¶æœŸçš„è¶…ç¨³å®šä¼ å¯¼å…³ç³»ï¼š")
        print("-" * 80)
        for idx, row in stable_all.head(20).iterrows():
            lead_name = row.get('sector_lead_name', row['sector_lead'])
            lag_name = row.get('sector_lag_name', row['sector_lag'])
            periods_str = ', '.join(row['period_name'])
            print(f"  {lead_name} â†’ {lag_name}")
            print(f"    å¹³å‡ç›¸å…³ç³»æ•°: {row['correlation']:.3f}")
            print(f"    å¹³å‡æ»åå¤©æ•°: {row['lag_days']:.1f}")
            print(f"    å‡ºç°æ—¶æœŸ: {periods_str}")
            print()
    else:
        print("\nâš ï¸  æ²¡æœ‰åœ¨æ‰€æœ‰æ—¶æœŸå‡å‡ºç°çš„ä¼ å¯¼å…³ç³»")

    if len(stable_half) > 0:
        print(f"\nğŸ“Š å‡ºç°åœ¨ â‰¥{total_periods // 2} ä¸ªæ—¶æœŸçš„ç¨³å®šä¼ å¯¼å…³ç³»ï¼ˆå‰20ä¸ªï¼‰ï¼š")
        print("-" * 80)
        display_df = stable_half.head(20).copy()

        for idx, row in display_df.iterrows():
            lead_name = row.get('sector_lead_name', row['sector_lead'])
            lag_name = row.get('sector_lag_name', row['sector_lag'])
            print(f"  {lead_name} â†’ {lag_name}")
            print(f"    å‡ºç°æ¬¡æ•°: {row['appearance_count']}/{total_periods}")
            print(f"    å¹³å‡ç›¸å…³ç³»æ•°: {row['correlation']:.3f}")
            print(f"    å¹³å‡æ»åå¤©æ•°: {row['lag_days']:.1f}")
            periods_str = ', '.join(row['period_name'])
            print(f"    æ—¶æœŸ: {periods_str}")
            print()

    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_dir = project_root / "output" / "full_history_l3_analysis"
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜åŸå§‹æ•°æ®
    combined_df.to_csv(output_dir / f"full_history_{level}_all_periods.csv",
                       index=False, encoding='utf-8-sig')

    # ä¿å­˜ç¨³å®šæ€§åˆ†æç»“æœ
    pair_counts.to_csv(output_dir / f"full_history_{level}_stability.csv",
                       index=False, encoding='utf-8-sig')

    # ç”ŸæˆMarkdownæŠ¥å‘Š
    generate_report(
        periods=periods,
        combined_df=combined_df,
        pair_counts=pair_counts,
        stable_all=stable_all,
        stable_half=stable_half,
        level=level,
        min_correlation=min_correlation,
        output_dir=output_dir
    )

    print(f"\nâœ… åˆ†æå®Œæˆï¼")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    print(f"   - åŸå§‹æ•°æ®: full_history_{level}_all_periods.csv")
    print(f"   - ç¨³å®šæ€§æ•°æ®: full_history_{level}_stability.csv")
    print(f"   - åˆ†ææŠ¥å‘Š: full_history_report_{level}.md")


def generate_report(periods, combined_df, pair_counts, stable_all, stable_half,
                   level, min_correlation, output_dir):
    """ç”ŸæˆMarkdownæŠ¥å‘Š"""

    report_lines = []
    report_lines.append(f"# æ¿å—ä¼ å¯¼å…³ç³»å…¨å†å²åˆ†ææŠ¥å‘Š - {level}å±‚çº§")
    report_lines.append("")
    report_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append("")
    report_lines.append(f"**åˆ†ææ–¹æ³•**: è¶…é¢æ”¶ç›Šæ³•ï¼ˆå‰”é™¤å¸‚åœºæ•ˆåº”ï¼‰")
    report_lines.append(f"**æœ€å°ç›¸å…³ç³»æ•°**: {min_correlation}")
    report_lines.append("")

    # 1. å„æ—¶æœŸä¼ å¯¼å…³ç³»æ•°é‡
    report_lines.append("## å„æ—¶æœŸä¼ å¯¼å…³ç³»æ•°é‡")
    report_lines.append("")
    report_lines.append("| æ—¶æœŸ | èµ·æ­¢æ—¥æœŸ | å¸‚åœºç‰¹å¾ | ä¼ å¯¼å¯¹æ•° |")
    report_lines.append("|------|---------|---------|----------|")

    for period in periods:
        period_data = combined_df[combined_df['period_name'] == period['name']]
        count = len(period_data)
        date_range = f"{period['start'][:4]}/{period['start'][4:6]}/{period['start'][6:]}~{period['end'][:4]}/{period['end'][4:6]}/{period['end'][6:]}"
        report_lines.append(f"| {period['name']} | {date_range} | {period['description']} | {count} |")

    report_lines.append("")

    # 2. ç¨³å®šæ€§ç»Ÿè®¡
    total_periods = len(periods)
    report_lines.append("## ç¨³å®šæ€§åˆ†æ")
    report_lines.append("")
    report_lines.append(f"- **åˆ†ææ—¶æœŸæ•°**: {total_periods}")
    report_lines.append(f"- **æ€»ä¼ å¯¼å¯¹æ•°**: {len(pair_counts)}")
    report_lines.append(f"- **å‡ºç°åœ¨æ‰€æœ‰æ—¶æœŸ**: {len(stable_all)} å¯¹")
    report_lines.append(f"- **å‡ºç°åœ¨â‰¥ä¸€åŠæ—¶æœŸ**: {len(stable_half)} å¯¹")
    report_lines.append("")

    # 3. è¶…ç¨³å®šä¼ å¯¼å…³ç³»
    if len(stable_all) > 0:
        report_lines.append("## è¶…ç¨³å®šä¼ å¯¼å…³ç³»ï¼ˆæ‰€æœ‰æ—¶æœŸå‡å‡ºç°ï¼‰")
        report_lines.append("")
        report_lines.append("| æ’å | é¢†æ¶¨æ¿å— | è·Ÿéšæ¿å— | å‡ºç°æ¬¡æ•° | å¹³å‡ç›¸å…³ç³»æ•° | å¹³å‡æ»åå¤©æ•° |")
        report_lines.append("|------|----------|----------|----------|--------------|-------------|")

        for idx, (_, row) in enumerate(stable_all.head(20).iterrows(), 1):
            lead_name = row.get('sector_lead_name', row['sector_lead'])
            lag_name = row.get('sector_lag_name', row['sector_lag'])
            report_lines.append(
                f"| {idx} | {lead_name} | {lag_name} | "
                f"{row['appearance_count']}/{total_periods} | "
                f"{row['correlation']:.3f} | {row['lag_days']:.1f} |"
            )
        report_lines.append("")
    else:
        report_lines.append("## è¶…ç¨³å®šä¼ å¯¼å…³ç³»")
        report_lines.append("")
        report_lines.append("**âš ï¸  æ²¡æœ‰åœ¨æ‰€æœ‰æ—¶æœŸå‡å‡ºç°çš„ä¼ å¯¼å…³ç³»**")
        report_lines.append("")

    # 4. è¾ƒç¨³å®šä¼ å¯¼å…³ç³»
    if len(stable_half) > 0:
        report_lines.append(f"## è¾ƒç¨³å®šä¼ å¯¼å…³ç³»ï¼ˆå‡ºç°åœ¨â‰¥{total_periods // 2}ä¸ªæ—¶æœŸï¼‰")
        report_lines.append("")
        report_lines.append("| æ’å | é¢†æ¶¨æ¿å— | è·Ÿéšæ¿å— | å‡ºç°æ¬¡æ•° | å‡ºç°æ—¶æœŸ | å¹³å‡ç›¸å…³ç³»æ•° | å¹³å‡æ»åå¤©æ•° |")
        report_lines.append("|------|----------|----------|----------|----------|--------------|-------------|")

        for idx, (_, row) in enumerate(stable_half.head(30).iterrows(), 1):
            lead_name = row.get('sector_lead_name', row['sector_lead'])
            lag_name = row.get('sector_lag_name', row['sector_lag'])
            periods_str = ','.join(row['period_name'])
            report_lines.append(
                f"| {idx} | {lead_name} | {lag_name} | "
                f"{row['appearance_count']}/{total_periods} | {periods_str} | "
                f"{row['correlation']:.3f} | {row['lag_days']:.1f} |"
            )
        report_lines.append("")

    # 5. å„æ—¶æœŸæœ€å¼ºä¼ å¯¼å…³ç³»
    report_lines.append("## å„æ—¶æœŸæœ€å¼ºä¼ å¯¼å…³ç³» Top 5")
    report_lines.append("")

    for period in periods:
        period_data = combined_df[combined_df['period_name'] == period['name']]

        if len(period_data) == 0:
            continue

        report_lines.append(f"### {period['name']} ({period['description']})")
        report_lines.append("")
        report_lines.append("| æ’å | é¢†æ¶¨æ¿å— | è·Ÿéšæ¿å— | æ»åå¤©æ•° | ç›¸å…³ç³»æ•° |")
        report_lines.append("|------|----------|----------|----------|----------|")

        top_5 = period_data.nlargest(5, 'correlation')
        for idx, (_, row) in enumerate(top_5.iterrows(), 1):
            lead_name = row.get('sector_lead_name', row['sector_lead'])
            lag_name = row.get('sector_lag_name', row['sector_lag'])
            report_lines.append(
                f"| {idx} | {lead_name} | {lag_name} | "
                f"{row['lag_days']} | {row['correlation']:.3f} |"
            )
        report_lines.append("")

    # 6. ç»“è®º
    report_lines.append("## åˆ†æç»“è®º")
    report_lines.append("")

    if len(stable_all) == 0:
        report_lines.append("1. **é•¿æœŸç¨³å®šæ€§åˆ†æ**ï¼šæ²¡æœ‰ä¼ å¯¼å…³ç³»åœ¨å…¨éƒ¨7ä¸ªæ—¶æœŸï¼ˆ26å¹´ï¼‰å‡å‡ºç°")
        report_lines.append("")

    if len(stable_half) > 0:
        report_lines.append(f"2. **ä¸­æœŸç¨³å®šæ€§**ï¼š{len(stable_half)}ä¸ªä¼ å¯¼å¯¹å‡ºç°åœ¨â‰¥{total_periods // 2}ä¸ªæ—¶æœŸ")
        report_lines.append("")

    report_lines.append("3. **L3 vs L1 å¯¹æ¯”**ï¼š")
    report_lines.append("   - L3ç»†åˆ†è¡Œä¸šä¼ å¯¼å…³ç³»æ›´å…·ä½“ã€æ›´ç¨³å®š")
    report_lines.append("   - L3èƒ½å¤Ÿæ•æ‰çœŸå®çš„äº§ä¸šé“¾ä¸Šä¸‹æ¸¸å…³ç³»")
    report_lines.append("   - ç›¸å…³æ€§å¼ºåº¦æ˜¾è‘—é«˜äºL1å±‚çº§")
    report_lines.append("")

    # å†™å…¥æ–‡ä»¶
    report_path = output_dir / f"full_history_report_{level}.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))


if __name__ == '__main__':
    main()
